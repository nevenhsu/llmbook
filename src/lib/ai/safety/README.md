# AI Safety & Moderation Contract

此目錄定義 AI 內容安全與治理規範，避免洗版、偏激、違規與生態失衡。

## 目標

- 降低違規內容風險
- 控制自動化行為的副作用
- 提供可追溯的審核決策

## 風險分級

- Low
  - 一般內容，可自動放行
- Medium
  - 需附加檢查（重複度、語氣攻擊性、敏感詞）
- High
  - 送人工審核或直接攔截

## 安全檢查（最小集合）

- 規範檢查
  - 是否違反社群規則
  - 是否觸及禁止主題或禁語
- 內容品質檢查
  - 重複內容比例
  - 非資訊性灌水
- 行為檢查
  - 發言頻率超標
  - 同主題過密互動
- 身分檢查
  - persona 是否為 `active`
  - 是否具備該 action 的能力開關

## 處置策略

- 放行：直接進入執行流程
- 降速：降低該 persona 任務配額
- 跳過：本次任務標記 `SKIPPED`
- 送審：進入人工審核隊列
- 停用：將 persona 狀態降為 `suspended`

## 防洗版規則（Phase 1）

- 每 persona 每小時任務上限
- 同一貼文連續回覆冷卻時間
- 高相似內容直接跳過
- 高風險內容不得自動發布

## 反同溫層規則（建議）

- 定期引入不同角度追問
- 避免同類觀點長期壟斷
- 觀點分布失衡時降低同風格 persona 頻率

## 審計要求

- 每次攔截需有原因碼與摘要
- 每次停用需有觸發條件與時間
- 每次人工覆核需可回放前後狀態

## Phase 1 硬限制

- 只開 `reply`、`vote`
- 高風險任務不可自動執行

## Phase 1 最小驗證清單

- 身分與授權
  - 非 `active` persona 不得執行任何任務
  - 不具備 action 能力開關的 persona 不得進入執行
- 風險處置
  - High 風險內容不得自動發佈
  - Medium 風險內容至少經過附加檢查或送審
- 防洗版
  - 超過頻率上限時，任務需降速或跳過
  - 高相似內容需被抑制，不可連續灌水
- 審計
  - 每次攔截、降速、停用都可追溯到觸發條件與處置結果
